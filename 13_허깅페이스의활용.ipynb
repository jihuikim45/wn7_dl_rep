{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3e4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124 cuda: 12.4 is_available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__, \n",
    "      \"cuda:\", torch.version.cuda, \n",
    "      \"is_available:\", \n",
    "      torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb82c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217cd818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa065c0",
   "metadata": {},
   "source": [
    "# inference api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2a1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "result = client.translation(\n",
    "    \"Меня зовут Вольфганг и я живу в Берлине\",\n",
    "    model=\"Helsinki-NLP/opus-mt-ko-en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b150534",
   "metadata": {},
   "source": [
    "# pipeline()\n",
    "task : 텍스트 기반한 감성분석, 분류(제로샷), 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67c2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9459660053253174}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\") # task 지정\n",
    "classifier(\"Second-run films emerge as box office lifeline amid Korean film industry slump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1e6f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Neutral', 'score': 0.6539700031280518}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", \"tabularisai/multilingual-sentiment-analysis\") # task 지정\n",
    "classifier(\"Second-run films emerge as box office lifeline amid Korean film industry slump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2efc613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Neutral', 'score': 0.8508070707321167}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", \"tabularisai/multilingual-sentiment-analysis\") # task 지정\n",
    "classifier(\"2차 영화, 한국 영화 산업 침체 속에서 흥행 생명선으로 떠오르다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c745b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.20029573142528534,\n",
       "  'token': 42428,\n",
       "  'token_str': '영화',\n",
       "  'sequence': '2차 영화, 영화 산업 침체 속에서 흥행 생명선으로 떠오르다'},\n",
       " {'score': 0.06603540480136871,\n",
       "  'token': 23130,\n",
       "  'token_str': '일본',\n",
       "  'sequence': '2차 영화, 일본 산업 침체 속에서 흥행 생명선으로 떠오르다'},\n",
       " {'score': 0.042990636080503464,\n",
       "  'token': 48556,\n",
       "  'token_str': '한국',\n",
       "  'sequence': '2차 영화, 한국 산업 침체 속에서 흥행 생명선으로 떠오르다'},\n",
       " {'score': 0.04271746799349785,\n",
       "  'token': 10232,\n",
       "  'token_str': '...',\n",
       "  'sequence': '2차 영화,... 산업 침체 속에서 흥행 생명선으로 떠오르다'},\n",
       " {'score': 0.0172389205545187,\n",
       "  'token': 101660,\n",
       "  'token_str': '도시',\n",
       "  'sequence': '2차 영화, 도시 산업 침체 속에서 흥행 생명선으로 떠오르다'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"fill-mask\", \"bert-base-multilingual-cased\") # task 지정\n",
    "classifier(\"2차 영화, [MASK] 산업 침체 속에서 흥행 생명선으로 떠오르다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650f40e",
   "metadata": {},
   "source": [
    "# \"question-answering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e9ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 663.03it/s]\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949767470359802, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", \"distilbert-base-cased-distilled-squad\")  # 질의 응답\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b0931",
   "metadata": {},
   "source": [
    "# \"ner\" 개체명 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b753849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9981694),\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9796019),\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9932106),\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "ner = pipeline(\"ner\", \"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)  # 개체명 인식\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008efee",
   "metadata": {},
   "source": [
    "# \"summarization\" 문장요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f5cb345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (425 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': '할리우드는 박스오피스 수치를 높이기 위해 고전 영화를 활용하고 있는데 대부분의 경우 최근 재개봉작이 현대 관객들에게 좋은 성과를 거두면서 성공적인 것으로 입증되고 있다.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ = pipeline(\"summarization\", \"eenzeenee/t5-base-korean-summarization\")\n",
    "summ(\"\"\"KOFIC은 2024년 재개봉 영화 수가 228편으로 전년 대비 80편 증가했다고 보고했다.\n",
    "     이들 영화의 수익은 1년 전보다 16.1% 증가한 245억원(1,757만 달러)에 달했고, 재개봉 영화 관객수는 2023년보다 29.9% 증가한 250만 명이다.\n",
    "     이러한 추세는 세계 최대 규모의 북미 시장에서도 뚜렷하게 드러납니다. \n",
    "     영화감독 스티븐 스필버그의 '죠스'는 개봉 50주년을 기념해 8월 29일 재개봉한 영화 제작자 스티븐 스필버그의 '죠스'는 노동절 주말 박스오피스 9,800만 달러를 기록해 \n",
    "     신작에 이어 2위를 차지하며 지난 10년 동안 재개봉 영화 중 최고의 성적을 달성했습니다.할리우드는 박스오피스 수치를 높이기 위해 점점 더 고전 영화를 활용하고 있습니다. \n",
    "     대부분의 경우 이 전략은 \"Hocus Pocus\"(1993) 및 \"Coraline\"(2009)과 같은 최근 재개봉작이 현대 관객들에게 좋은 성과를 거두면서 성공적인 것으로 입증되고 있습니다. \n",
    "     1985년 고전 \"백 투 더 퓨처\"의 40주년 기념 상영을 포함하여 가까운 장래에 더 많은 고전 재개봉이 계획되어 있습니다.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abcc81e",
   "metadata": {},
   "source": [
    "# \"translation\" 한글 → 영어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f812c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ko-en\")  # 한국어 -> 영어번역\n",
    "translator(\"이 문장을 영어로 번역해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380607c7",
   "metadata": {},
   "source": [
    "# image-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86dcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "imagetotext = pipeline(\"image-to-text\", \"ydshieh/vit-gpt2-coco-en\")\n",
    "imagetotext(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\", max_new_tokens=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f9ed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True marian\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "tok = AutoTokenizer.from_pretrained(name, token=None)\n",
    "model = AutoModelForSeq2SeqLM. from_pretrained(name, token=None)\n",
    "print(tok is not None, model.config.model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827712ac",
   "metadata": {},
   "source": [
    "# fine tuning 을 위한 AutoClass 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9e996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('imdb')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7360d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:14<00:00, 3546.16 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 - 모델\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def preprocess_f(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "tokenizer_datasets = dataset.map(preprocess_f, batched=True)\n",
    "tokenizer_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319c5fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080621bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 386/7815 05:32 < 1:47:14, 1.15 it/s, Epoch 0.25/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m      3\u001b[0m tr_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      4\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2e-5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     13\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[0;32m     14\u001b[0m     args \u001b[38;5;241m=\u001b[39m tr_args,\n\u001b[0;32m     15\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m tokenizer_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     16\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m tokenizer_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\transformers\\trainer.py:2328\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\transformers\\trainer.py:2677\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2671\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m   2672\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2675\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2676\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m-> 2677\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2678\u001b[0m ):\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습설정\n",
    "from transformers import TrainingArguments, Trainer\n",
    "tr_args = TrainingArguments(\n",
    "    output_dir = './results',\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = tr_args,\n",
    "    train_dataset = tokenizer_datasets['train'],\n",
    "    eval_dataset = tokenizer_datasets['test']\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "trainer.evaluate()\n",
    "# 저장\n",
    "model_path = './fine_tuned_distilbert_imdb'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf74269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장모델 로드\n",
    "# 토크나이저 로드 .from_pretrained\n",
    "# 모델로드\n",
    "# 모델.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  3185,  2001,  7078, 10392,   999,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장 모델로 추론하기\n",
    "input_text = 'This movie was absolutely fantastic!'\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1053d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b285233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과 : 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad(): #역전파x, 추론 only\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "predict_class_id = torch.argmax(outputs.logits, dim =-1).item()\n",
    "print(f'예측 결과 : {predict_class_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd82d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
